---

- hosts: all
  vars:
    fluentd:
      td_agent_version: '2.0'
      td_agent_architecture: 'amd64'
      config_dir: /etc/td-agent/conf.d
      pid_file: /var/run/td-agent/td-agent.pid
      log_dir: /mnt/logs/td-agent
      user: td-agent
      group: td-agent
      # aws specific info for uploading logs to s3
      aws:
        # override above s3 credentials if different
        aws_access_key_id: "{{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
        aws_secret_access_key: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
        # bucket where s3 data will be archived
        s3_bucket: balanced-logs-{{ aws_region }}
        # which s3 endpoint to use to archive data
        s3_endpoint: s3.amazonaws.com
      # list of kafka servers [127.0.0.1:9999, ...]
      kakfa:
        servers: []
      in_forward:
        port: 24224
        bind: 0.0.0.0
        servers: []
      in_tail:
        files: []
        transforms: []
      sources: []
      matches: []
      plugins: []
      services: {}
    fluentd_sources:
      - priority: 20
        name: forwarding
        options: {}
    fluentd_matches:
      - priority: 05
        name: reformer
        options: {}
      - priority: 06
        name: reformer
        options:
          tag: header['channel']
      - priority: 10
        name: debug
        options:
          pattern: 'debug.**'
    fluentd_plugins:
      - fluent-plugin-record-reformer
      - fluent-plugin-kafka
    # this file is used to debug any issues you may have. see README for how to
    # utilize.
    fluentd_in_tail_files:
      - name: debug.log
        path: /var/log/td-agent/debug.log
        format: json

  vars_files:
    - "infras/global/vars/{{ aws_account }}.yml"
    - "infras/global/vars/{{ aws_account }}_{{ aws_region }}.yml"
    - "infras/global/vars/{{ aws_account }}_{{ infra_env }}.yml"
    - "vars/{{ aws_account }}.yml"
    - "vars/{{ aws_account }}_{{ infra_env }}.yml"
  roles:
    - base
    - ntp
    - td-agent
    - newrelic
    - fluentd
